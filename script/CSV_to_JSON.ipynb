{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSV_to_JSON.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956gWvgHK2tN"
      },
      "source": [
        "# Data management: Conversion and integration of csv files on flights, airports and airlines into json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuEL7aOMgT6F"
      },
      "source": [
        " # Installing libraries not present in google colab but necessaries for \r\n",
        " # this script. You can skip this if you already have this libreries!\r\n",
        " !pip install --upgrade jsonschema\r\n",
        " !pip install --upgrade pymongo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou0BBqAHf8xm"
      },
      "source": [
        "import pandas as pd  # for csv reader\r\n",
        "import numpy as np  # for checking NaN values\r\n",
        "import json\r\n",
        "import jsonschema\r\n",
        "from jsonschema import validate, Draft7Validator # pip install --upgrade jsonschema\r\n",
        "import os\r\n",
        "import time\r\n",
        "# importing pymongo library\r\n",
        "import pymongo\r\n",
        "from pymongo import MongoClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byqKS5yjIl46"
      },
      "source": [
        "## MongoDB connection\r\n",
        "Change these settings with your local machine settings. In my version I created \r\n",
        "a docker container with mongo db and a collection with 3 shards for the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNB2DDjTIlqq"
      },
      "source": [
        "# Connecting to mongo client. Change arguments according to your machine \r\n",
        "client = MongoClient('mongos1', 27017)\r\n",
        "# get the instance of BTS database\r\n",
        "mongoDB = client.BTS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4TB6iJXjhsp"
      },
      "source": [
        "### Testing mongo database with some queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPkdJMs3jilH"
      },
      "source": [
        "def query_execution():\r\n",
        "  \"\"\"\r\n",
        "    query_execution() execute four different query on mongoDB and print result\r\n",
        "    and time of execution!\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  \r\n",
        "  # Query1: return the total average of all flights\r\n",
        "  start_time = time.time()\r\n",
        "  results = mongoDB.flight.aggregate([{\"$unwind\": \"$flights\"}, \r\n",
        "                                      {\"$group\": {\"_id\": \"_id\", \r\n",
        "                                                  \"tot_avg_delay\": {\"$avg\": \"$flights.arr_delay\"}}}, \r\n",
        "                                      {\"$project\": {\"_id\":0, \"tot_avg_delay\":1}}])\r\n",
        "  print(\"Query1 result: \" + results)\r\n",
        "  print(\"Query1 seconds: %s \" % (time.time() - start_time))\r\n",
        "\r\n",
        "  # Query2: return the total average of all flights for the airline EV\r\n",
        "  start_time = time.time()\r\n",
        "  results = mongoDB.flight.aggregate([{\"$match\": {\"flights.airline\": \"EV\"}},\r\n",
        "                                      {\"$unwind\": \"$flights\"}, \r\n",
        "                                      {\"$match\": {\"flights.airline\": \"EV\"}}, \r\n",
        "                                      {\"$group\": {\"_id\": \"_id\", \r\n",
        "                                                  \"average\": {\"$avg\": \"$flights.arr_delay\"}}}, \r\n",
        "                                      {\"$project\": {\"_id\":0, \"average\":1}}])\r\n",
        "  print(\"Query2 result: \" + results)\r\n",
        "  print(\"Query2 seconds: %s \" % (time.time() - start_time))\r\n",
        "\r\n",
        "  # Query3: return the total average for the flight between SFO and LAX\r\n",
        "  start_time = time.time()\r\n",
        "  results = mongoDB.flight.aggregate([{\"$match\": {\"origin\": \"SFO\", \"destination\": \"LAX\"}},\r\n",
        "                                      {\"$unwind\": \"$flights\"},  \r\n",
        "                                      {\"$group\": {\"_id\": \"_id\", \r\n",
        "                                                  \"average\": {\"$avg\": \"$flights.arr_delay\"}}}, \r\n",
        "                                      {\"$project\": {\"_id\":0, \"average\":1}}])\r\n",
        "  print(\"Query3 result: \" + results)\r\n",
        "  print(\"Query3 seconds: %s \" % (time.time() - start_time))\r\n",
        "\r\n",
        "\r\n",
        "  # Query4: return the total average of all flights ffor the year 2018\r\n",
        "  start_time = time.time()\r\n",
        "  results = mongoDB.flight.aggregate([{\"$match\": {\"year\": 2018}}, \r\n",
        "                                      {\"$unwind\": \"$flights\"}, \r\n",
        "                                      {\"$group\": {\"_id\": \"_id\",\r\n",
        "                                                  \"average\": {\"$avg\": \"$flights.arr_delay\"}}}, \r\n",
        "                                      {\"$project\": {\"_id\":0, \"average\":1}}])\r\n",
        "  print(\"Query4 result: \" + results)\r\n",
        "  print(\"Query4 seconds: %s \" % (time.time() - start_time))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPlw1UuQ7wmS"
      },
      "source": [
        "## Create validator for json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lfHAHtMk-VM"
      },
      "source": [
        "# load json schema for validate files\r\n",
        "json_schema = json.loads(open('./Json-schema/JsonFlightSchema.json').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWdb-tFintSm"
      },
      "source": [
        "def json_validator(json_schema, json_data):\r\n",
        "  \"\"\"\r\n",
        "    validateJson() validates a json file against a proper schema\r\n",
        "\r\n",
        "\r\n",
        "    :param json_schema: schema file for validating json data file\r\n",
        "    :param json_data: file json to validate\r\n",
        "    :return: True if file is valid against schema, False otherwise\r\n",
        "  \"\"\" \r\n",
        "\r\n",
        "  # try to validate json data\r\n",
        "  try:\r\n",
        "    Draft7Validator(json_schema).validate(json_data)\r\n",
        "  except jsonschema.exceptions.ValidationError as err:\r\n",
        "    return False\r\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKe0Vmi0C8jK"
      },
      "source": [
        "## Data loading and preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNNmx4eeANeW"
      },
      "source": [
        "def is_NaN(val):\r\n",
        "  \"\"\"\r\n",
        "    is_NaN() check if a value is null for string and float types\r\n",
        "\r\n",
        "    :param val: value to check\r\n",
        "    :return: True if value is NaN or NaT or null, False otherwise\r\n",
        "  \"\"\" \r\n",
        "\r\n",
        "  # check string NaN\r\n",
        "  if isinstance(val, str) and not (val == '' or pd.isnull(val)):\r\n",
        "    return False\r\n",
        "  # check NaT/NaN value for date\r\n",
        "  elif not pd.isnull(val):\r\n",
        "    return False\r\n",
        "\r\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6M-QLVTFaci"
      },
      "source": [
        "#### Airlines data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBdJAMizRI3"
      },
      "source": [
        "# get confidence with airline data\r\n",
        "temp = pd.read_csv('./CSV-File/CSV-for-integration/airlines.csv')\r\n",
        "temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6yKCBoyprEg"
      },
      "source": [
        "def create_airlines_dictionary():\r\n",
        "  \"\"\"\r\n",
        "    create_airlines_dictionary() loads airline data and create a key-value \r\n",
        "    dictionary containing IATA-name pairs\r\n",
        "\r\n",
        "    :return: Dictionary contains pairs with IATA codes and airline's name\r\n",
        "  \"\"\" \r\n",
        "\r\n",
        "  # reading airline data \r\n",
        "  data_airlines = pd.read_csv('./CSV-File/CSV-for-integration/airlines.csv')\r\n",
        "\r\n",
        "  airlines_dictionary = {}\r\n",
        "  # for each line if IATA code is valid create a pair with airline's name\r\n",
        "  # key = airline's IATA code, value = airline's name\r\n",
        "  for line in data_airlines.itertuples(index=False): \r\n",
        "    if not is_NaN(line.IATA) and line.IATA != \"-\":\r\n",
        "      airlines_dictionary[line.IATA.upper()] = line.Name\r\n",
        "  \r\n",
        "  return(airlines_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2em8kz7nFeAe"
      },
      "source": [
        "#### Airports data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMw4qiwQwkHZ"
      },
      "source": [
        "# get confidence with airport data\r\n",
        "temp = pd.read_csv('./CSV-File/CSV-for-integration/airports.csv')\r\n",
        "temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qrFvZKVvxvM"
      },
      "source": [
        "def create_airport_dictionary():\r\n",
        "  \"\"\"\r\n",
        "    create_airport_dictionary() loads airport data and create a key-value \r\n",
        "    dictionary which contains key value pairs where:\r\n",
        "    key: airport's iata code\r\n",
        "    value: list of values as follow [icao code, name, airport type, \r\n",
        "                                     elevation_ft, latitude, longitude]\r\n",
        "\r\n",
        "    :return: Dictionary contains pairs with IATA codes and a list of information\r\n",
        "             for the airport\r\n",
        "  \"\"\" \r\n",
        "\r\n",
        "  # reading airline data \r\n",
        "  data_airport = pd.read_csv('./CSV-File/CSV-for-integration/airports.csv')\r\n",
        "\r\n",
        "  airport_dictionary = {}\r\n",
        "  # for each line if IATA code is valid create a pair with airport's info\r\n",
        "  # key = airport's IATA code\r\n",
        "  # value: [icao, name, type, elevation_ft, latitude, longitude]\r\n",
        "  for line in data_airport.itertuples(index=False): \r\n",
        "    if not is_NaN(line.iata_code):\r\n",
        "      longi, lati = line.coordinates.split(\",\", 1)\r\n",
        "      airport_dictionary[line.iata_code.upper()] = [line.gps_code, line.name,\r\n",
        "                                               line.type, line.elevation_ft,\r\n",
        "                                               float(lati), float(longi)]\r\n",
        "  \r\n",
        "  return(airport_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZcQfEWRFf-8"
      },
      "source": [
        "#### Top 50 airports passengers data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJox7d7uFMah"
      },
      "source": [
        "# get confidence with passengers data\r\n",
        "col_names=['world_ranking', 'USA_ranking', 'country', 'city_state', \r\n",
        "           'IATA', 'tot_passengers', 'growth_percent'] \r\n",
        "\r\n",
        "temp = pd.read_excel('./CSV-File/CSV-for-integration/Passengers_2019.xlsx',header=2, names=col_names)\r\n",
        "temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRamLqr4ETwx"
      },
      "source": [
        "def create_passengers_dictionary():\r\n",
        "  \"\"\"\r\n",
        "    create_passengers_dictionary() loads airport passengers data and create a \r\n",
        "    key-value dictionary which contains key value pairs where:\r\n",
        "    key: airport's iata code\r\n",
        "    value: list of values as follow [\"year;world_ranking;tot_passengers;growth_percent\", ...]\r\n",
        "\r\n",
        "    :return: Dictionary contains pairs with IATA codes and a list of passengers \r\n",
        "             data for the airport\r\n",
        "  \"\"\" \r\n",
        "\r\n",
        "  # define column names for the dataFrame \r\n",
        "  col_names=['world_ranking', 'USA_ranking', 'country', 'city_state', 'IATA', \r\n",
        "            'tot_passengers', 'growth_percent'] \r\n",
        "\r\n",
        "\r\n",
        "  airport_passengers_dict = {}\r\n",
        "  # read passengers data from file for 2018 and 2019\r\n",
        "  for i in range(2018,2020):\r\n",
        "    # reading excel data\r\n",
        "    data_ap = pd.read_excel('./CSV-File/CSV-for-integration/Passengers_' + str(i) + '.xlsx',\r\n",
        "                                            header=2, names=col_names)\r\n",
        "    \r\n",
        "    # For each line in the file, it adds the information to the dictionary \r\n",
        "    for line in data_ap.itertuples(index=False): \r\n",
        "      # corret growth info, because some file is in % and others not\r\n",
        "      if line[6] < 0.1:\r\n",
        "        growth = line[6]*100\r\n",
        "      else:\r\n",
        "        growth = line[6]\r\n",
        "\r\n",
        "      # create string by concatenate information\r\n",
        "      to_add = str(i) + \";\" + str(line[0]) + \";\" + str(line[5]) + \";\" + str(growth)\r\n",
        "      # get airport iata code\r\n",
        "      airport_iata = line[4].upper()\r\n",
        "\r\n",
        "      # check if the code already exist and append or create the values for the key\r\n",
        "      if airport_iata in airport_passengers_dict.keys():\r\n",
        "        (airport_passengers_dict[airport_iata]).append(to_add)\r\n",
        "      else:\r\n",
        "        airport_passengers_dict[airport_iata] = [to_add]\r\n",
        "      \r\n",
        "\r\n",
        "  return airport_passengers_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9VKi6HuFkA-"
      },
      "source": [
        "#### Flights data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7qV5c5xCSwb"
      },
      "source": [
        "# get confidence with data\r\n",
        "temp = pd.read_csv(\"./CSV-File/BTS-FlightData/2018_1.csv\", usecols=list(range(0, 32)))\r\n",
        "temp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hXjrZcf9_W"
      },
      "source": [
        "def load_flight_csv(filepath):\r\n",
        "  \"\"\"\r\n",
        "    load_flight_csv() Read the flight data files and prepare the dataset \r\n",
        "    for processing by converting the data fields to the right type \r\n",
        "\r\n",
        "    :param filepath: path from which to read the data \r\n",
        "    :return: Pandas dataframe with data\r\n",
        "  \"\"\" \r\n",
        "  \r\n",
        "  # read data from file\r\n",
        "  flight_data = pd.read_csv(filepath, usecols=list(range(0, 32)))\r\n",
        "  \r\n",
        "  # I don't convert here time because there are some lines with NaN values.\r\n",
        "  # NOTE: I save time as integer in json, so then I convert only line with valid values\r\n",
        "  \r\n",
        "  return flight_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zAr7uzZzrZy"
      },
      "source": [
        "## Data management: Creating JSON files and uploading into mongoDB \r\n",
        "Each files groups year, month, origin airport, destination airport and day of the week <br>\r\n",
        "(**NOTE:** year and month are grouped automatically as the files are already divided!) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4siN788851KN"
      },
      "source": [
        "### Create json section about airports info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JIOlIwcuVA7"
      },
      "source": [
        "# Init dictionaries for airlines, airports and passengers data\r\n",
        "airline_iata_name_dic = create_airlines_dictionary()\r\n",
        "airport_data_dic = create_airport_dictionary()\r\n",
        "airport_passengers_dic = create_passengers_dictionary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ6T64Wr0X9G"
      },
      "source": [
        "def json_airport_info(year, airport_code, str_city_state, str_state_name):\r\n",
        "  \"\"\"\r\n",
        "    json_airport_info() create a python dictionary with all the information \r\n",
        "    of a specific airport.\r\n",
        "\r\n",
        "    :param year: Reference year to eventually enter the list with passengers data \r\n",
        "    :param airport_code: IATA code of the airport\r\n",
        "    :param str_city_state: String consisting of \"CityName, stateCode\"\r\n",
        "    :param str_state_name: String consisting of \"StateName\"  \r\n",
        "    :return: Python dictionary with the followind data:\r\n",
        "             {ICAO, name, type, elevation_ft, latitude, longitude, city_name,\r\n",
        "             state_name, state_code}\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # save airport iata code as upper string\r\n",
        "  airport_iata = airport_code.upper()\r\n",
        "\r\n",
        "  # get all info from airport dictionary, I'm sure the airport code exists in the \r\n",
        "  # dictionary as a key otherwise I'd have to use a try-catch or an if statement\r\n",
        "  info_list = airport_data_dic[airport_iata]\r\n",
        "\r\n",
        "  # info_list = [icao, name, airport type, elevation_ft, latitude, longitude]\r\n",
        "\r\n",
        "  # split city name and state code\r\n",
        "  city, state_code = str_city_state.split(\",\", 1)\r\n",
        "\r\n",
        "  num_pass = []\r\n",
        "  # Check if the we have info about passengers for this airport\r\n",
        "  if airport_iata in airport_passengers_dic.keys():\r\n",
        "    single_pass = {}\r\n",
        "    \r\n",
        "    # check if this airport have info of passengers for one or more year,\r\n",
        "    # each year is saved as a string in a list into airport_passengers_dic\r\n",
        "    # with key = iata_code of the airport\r\n",
        "    # value = [\"year;world_ranking;tot_passengers;growth_percent\", ...]\r\n",
        "    for str_val in airport_passengers_dic[airport_iata]:\r\n",
        "      # split string of values\r\n",
        "      actual_year, rank, tot_pass, growth = str_val.split(\";\",4)\r\n",
        "\r\n",
        "      # If the year is <= the reference year I add it \r\n",
        "      # (i.e. If I am considering a 2018 flight I do not add info on 2019 passengers)\r\n",
        "      if int(actual_year) <= int(year):\r\n",
        "        single_pass[\"year\"] = int(actual_year)\r\n",
        "        single_pass[\"world_ranking\"] = int(rank)\r\n",
        "        single_pass[\"total_passengers\"] = int(tot_pass)\r\n",
        "        single_pass[\"growth_percent\"] = float(growth)\r\n",
        "\r\n",
        "    # append each year to the dictionary\r\n",
        "    num_pass.append(single_pass)\r\n",
        "\r\n",
        "  # create dictionary with airport info\r\n",
        "  airport_info = {\r\n",
        "      \"ICAO\": info_list[0],\r\n",
        "      \"name\": info_list[1],\r\n",
        "      \"type\": info_list[2],\r\n",
        "      \"elevation_ft\": int(info_list[3]),\r\n",
        "      \"latitude\": info_list[4],\r\n",
        "      \"longitude\": info_list[5],\r\n",
        "      \"city_name\": city,\r\n",
        "      \"state_name\": str_state_name,\r\n",
        "      \"state_code\": state_code.strip() # delete space\r\n",
        "  }\r\n",
        "\r\n",
        "  # If information exist I add the array with the info about passengers\r\n",
        "  if num_pass != []:\r\n",
        "    airport_info[\"num_passengers\"] = num_pass\r\n",
        "\r\n",
        "  return airport_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivE_tWX556yF"
      },
      "source": [
        "### Create json section about flights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YEE5Y2d0KJP"
      },
      "source": [
        "def json_single_flight(fligth_data):\r\n",
        "  \"\"\"\r\n",
        "    json_single_flight() create a python dictionary with all the information \r\n",
        "    of a specific flight. Only valid values will be added to the dictionary\r\n",
        "    (i.e. NaN/null/NaT values will not be add, refers to db schema)\r\n",
        "\r\n",
        "    :param fligth_data: flight data to parse\r\n",
        "    :return: Python dictionary of the data\r\n",
        "  \"\"\" \r\n",
        "\r\n",
        "  time_dic = {}\r\n",
        "\r\n",
        "  time_dic['day_of_month'] = fligth_data.DAY_OF_MONTH\r\n",
        "\r\n",
        "  # ailine's IATA code\r\n",
        "  airline_IATA_code = fligth_data.OP_CARRIER.upper()\r\n",
        "  time_dic['airline'] = airline_IATA_code\r\n",
        "   \r\n",
        "  # get the airline name from IATA codes by using the dictionary init before\r\n",
        "  if airline_IATA_code in airline_iata_name_dic.keys():\r\n",
        "    time_dic['airline_name'] = airline_iata_name_dic[airline_IATA_code]\r\n",
        "\r\n",
        "  # departure time. I save time field as integer, in this way it's more\r\n",
        "  # easy quering data from mongoDB\r\n",
        "  time_dic['crs_dep_time'] = int(fligth_data.CRS_DEP_TIME)\r\n",
        "\r\n",
        "  # saving departure time, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.DEP_TIME):\r\n",
        "    time_dic['dep_time'] = int(fligth_data.DEP_TIME)\r\n",
        "\r\n",
        "  # saving delay as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.DEP_DELAY):\r\n",
        "    time_dic['dep_delay'] = int(fligth_data.DEP_DELAY)\r\n",
        "\r\n",
        "  # saving dep delay group as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.DEP_DELAY_GROUP):\r\n",
        "    time_dic['dep_delay_group'] = int(fligth_data.DEP_DELAY_GROUP)\r\n",
        "\r\n",
        "  # arrival time (Does not contains NaN)\r\n",
        "  time_dic['crs_arr_time'] = int(fligth_data.CRS_ARR_TIME)\r\n",
        "\r\n",
        "  # saving arrival time, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ARR_TIME):\r\n",
        "    time_dic['arr_time'] = int(fligth_data.ARR_TIME)\r\n",
        "\r\n",
        "  # saving delay as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ARR_DELAY):\r\n",
        "    time_dic['arr_delay'] = int(fligth_data.ARR_DELAY)\r\n",
        "\r\n",
        "  # saving arrival delay group as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ARR_DELAY_GROUP):\r\n",
        "    time_dic['arr_delay_group'] = int(fligth_data.ARR_DELAY_GROUP)\r\n",
        "\r\n",
        "  # check if flight was cancelled (No NaN)\r\n",
        "  if fligth_data.CANCELLED == 1.0:\r\n",
        "    time_dic['cancelled'] = True\r\n",
        "    time_dic['cancellation_code'] = fligth_data.CANCELLATION_CODE\r\n",
        "  else:\r\n",
        "    time_dic['cancelled'] = False\r\n",
        "\r\n",
        "  # check if flight was diverted\r\n",
        "  if fligth_data.DIVERTED == 1.0:\r\n",
        "    time_dic['diverted'] = True\r\n",
        "  else:\r\n",
        "    time_dic['diverted'] = False\r\n",
        "\r\n",
        "  # saving crs Elapsed Time of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.CRS_ELAPSED_TIME):\r\n",
        "    time_dic['crs_elapsed_time'] = int(fligth_data.CRS_ELAPSED_TIME)\r\n",
        "\r\n",
        "  # saving real Elapsed Time of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ACTUAL_ELAPSED_TIME):\r\n",
        "    time_dic['actual_elapsed_time'] = int(fligth_data.ACTUAL_ELAPSED_TIME)\r\n",
        "\r\n",
        "  # saving air Time of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.AIR_TIME):\r\n",
        "    time_dic['air_time'] = int(fligth_data.AIR_TIME)\r\n",
        "\r\n",
        "  # saving carrier_delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.CARRIER_DELAY):\r\n",
        "    time_dic['carrier_delay'] = int(fligth_data.CARRIER_DELAY)\r\n",
        "\r\n",
        "  # saving weather delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.WEATHER_DELAY):\r\n",
        "    time_dic['weather_delay'] = int(fligth_data.WEATHER_DELAY)\r\n",
        "\r\n",
        "  # saving nas delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.NAS_DELAY):\r\n",
        "    time_dic['nas_delay'] = int(fligth_data.NAS_DELAY)\r\n",
        "\r\n",
        "  # saving security delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.SECURITY_DELAY):\r\n",
        "    time_dic['security_delay'] = int(fligth_data.SECURITY_DELAY)\r\n",
        "\r\n",
        "  # saving late aircraft delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.LATE_AIRCRAFT_DELAY):\r\n",
        "    time_dic['late_aircraft_delay'] = int(fligth_data.LATE_AIRCRAFT_DELAY)\t\r\n",
        "\r\n",
        "  return time_dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY4Rt_TL6EC5"
      },
      "source": [
        "### Create json basic structure for each .csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcKvNt41j6nh"
      },
      "source": [
        "def json_file_handler(json_dictionary, choice = 2):\r\n",
        "  \"\"\"\r\n",
        "    json_file_handler() manages  the json dictionary based on user's choice.\r\n",
        "    If choice == 1 then upload document on mongo db\r\n",
        "    if choice is 2 then save the document into a specific path\r\n",
        "    if choice == 3 then try to validate json file and return the result\r\n",
        "\r\n",
        "\r\n",
        "    :param json_dictionary: Json dictionary to manage\r\n",
        "    :param choice: user's choice for the function. Default choice is 2.\r\n",
        "\r\n",
        "    :return: If choice == 1 return True if document is inserted, False otherwise\r\n",
        "             If choice == 2 return None\r\n",
        "             If choice == 3 return True if document is validate, False otherwise.\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  os.makedirs(\"./Json-schema/sample\", exist_ok=True)   \r\n",
        "\r\n",
        "  if choice == 1:\r\n",
        "    # uploading document into mongoDB\r\n",
        "    try:\r\n",
        "        mongoDB.flight.insert_one(json_dictionary)\r\n",
        "        return True\r\n",
        "    except Exception as e:\r\n",
        "        print(\"An exception occurred ::\", e)\r\n",
        "        return False\r\n",
        "  elif choice == 2:\r\n",
        "    # writing document appending time for unique name\r\n",
        "    with open('./Json-schema/sample/sample' + str(time.time()) + '.json', 'w') as fp:\r\n",
        "      json.dump(json_dictionary, fp)\r\n",
        "    \r\n",
        "    return True\r\n",
        "  else:\r\n",
        "    # writing temporary file for validation\r\n",
        "    with open('./Json-schema/sample/temp.json', 'w') as fp:\r\n",
        "      json.dump(json_dictionary, fp)\r\n",
        "    f = open('./Json-schema/sample/temp.json',) \r\n",
        "    data = json.load(f) \r\n",
        "\r\n",
        "    # try to validate json file\r\n",
        "    res = json_validator(json_schema, data)\r\n",
        "\r\n",
        "    # Removing the temporary document\r\n",
        "    os.remove(\"./Json-schema/sample/temp.json\")\r\n",
        "    \r\n",
        "    return res\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6rVdkm_jhB5"
      },
      "source": [
        "def from_data_to_json(data_groups):\r\n",
        "  \"\"\"\r\n",
        "    from_data_to_json() create a json dictionary with all the information \r\n",
        "    about flights starting from the grouped data. \r\n",
        "    NOTE: in this file data_groups are group by year, month, day_of_week, origin, destinarion\r\n",
        "\r\n",
        "    :param data_groups: pandas groupby object that contains information \r\n",
        "                        about flight groups.\r\n",
        "    :return: Nothing, directly upload files to mongoDB.\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # Create a json file and upload it to mongo database for each group of \r\n",
        "  # day-origin-destination (Remember: each file contains a specific month and year)\r\n",
        "  for group in data_groups:\r\n",
        "    document = {}\r\n",
        "    # list of all flights for a specific day, origin and destination\r\n",
        "    flights = []\r\n",
        "    for flight in group[1].itertuples():\r\n",
        "      # Add basic information in case it is a new group\r\n",
        "      if document == {}:\r\n",
        "        document['year'] = flight.YEAR\r\n",
        "        document['month'] = flight.MONTH\r\n",
        "        document['day_of_week'] = flight.DAY_OF_WEEK\r\n",
        "        document['origin'] = flight.ORIGIN.upper()\r\n",
        "        document['origin_info'] = json_airport_info(flight.YEAR, flight.ORIGIN, \r\n",
        "                                                    flight.ORIGIN_CITY_NAME, \r\n",
        "                                                    flight.ORIGIN_STATE_NM)\r\n",
        "        document['destination'] = flight.DEST.upper()\r\n",
        "        document['destination_info'] = json_airport_info(flight.YEAR, flight.DEST, \r\n",
        "                                              flight.DEST_CITY_NAME, \r\n",
        "                                              flight.DEST_STATE_NM)\r\n",
        "        document['distance'] = int(flight.DISTANCE)\r\n",
        "        document['distance_group'] = flight.DISTANCE_GROUP\r\n",
        "      \r\n",
        "      # Append all flight information to the list\r\n",
        "      flights.append(json_single_flight(flight))\r\n",
        "\r\n",
        "    # add the list of all flight to the document\r\n",
        "    document['flights'] = flights\r\n",
        "\r\n",
        "    # Manage the json dictionary, \r\n",
        "    # 1 for upload into mongo, 2 for writing, 3 for test again schema\r\n",
        "    # please note that 2 is computationally expensive because create\r\n",
        "    # a milions of files!\r\n",
        "    json_file_handler(document, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPJtnG8XlnqL"
      },
      "source": [
        "# elaborate all flight files in the directory\r\n",
        "directory = \"./CSV-File/BTS-FlightData\"\r\n",
        "for filename in os.listdir(directory):\r\n",
        "  # printing feedback\r\n",
        "  print(\"Executing: \"  str(filename))\r\n",
        "\r\n",
        "  # reading data on flights \r\n",
        "  flight_df = load_flight_csv(directory + \"/\" + filename)\r\n",
        "  \r\n",
        "  # group data, each file already grouped by year and month too!\r\n",
        "  flight_df_groups = flight_df.groupby(['DAY_OF_WEEK', 'ORIGIN', 'DEST'])\r\n",
        "\r\n",
        "  # convert data to json and upload to mongoDB\r\n",
        "  from_data_to_json(flight_df_groups)\r\n",
        "  \r\n",
        "  # If you want to query the database step by step uncomment the following line\r\n",
        "  # query_execution()\r\n",
        "\r\n",
        "  # printing feedback\r\n",
        "  print(\"DONE: \" + str(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7uHFoX9azRp"
      },
      "source": [
        "# If you have used the second json for the function json_file_handler\r\n",
        "# and you want to download the zip file execute this line\r\n",
        "!zip -r json_file.zip ./Json-schema/sample/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpjlzlfmrhfM"
      },
      "source": [
        "# Try to execute some query on mongoDB and get result\r\n",
        "query_execution()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
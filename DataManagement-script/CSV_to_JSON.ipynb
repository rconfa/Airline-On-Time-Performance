{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSV_to_JSON.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956gWvgHK2tN"
      },
      "source": [
        "# <center> Data management: Conversion and integration of csv files on flights, airports and airlines into json files </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou0BBqAHf8xm"
      },
      "source": [
        "import pandas as pd  # for csv reader\r\n",
        "import datetime \r\n",
        "import numpy as np  # for checking NaN values\r\n",
        "import json\r\n",
        "import jsonschema\r\n",
        "from jsonschema import validate, RefResolver\r\n",
        "from jsonschema.validators import validator_for"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPlw1UuQ7wmS"
      },
      "source": [
        "## Create validator for json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUntJSLU88Ua"
      },
      "source": [
        "# define basic function to validate json data\r\n",
        "def validateJson(validator, jsonData):\r\n",
        "    try:\r\n",
        "        validator.validate(jsonData)\r\n",
        "    except jsonschema.exceptions.ValidationError as err:\r\n",
        "        return False\r\n",
        "    return True"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEzAicFj752R"
      },
      "source": [
        "# load all json schema\r\n",
        "airline = json.loads(open('./Json-schema/JsonAirlineSchema.json').read())\r\n",
        "airport = json.loads(open('/Json-schema/JsonAirportSchema.json').read())\r\n",
        "flight = json.loads(open('./Json-schema/JsonFlightSchema.json').read())"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DeflTm48E1r"
      },
      "source": [
        "#resolve reference for JsonFlightSchema\r\n",
        "schema_store = {\r\n",
        "  airline.get('$id','JsonAirlineSchema.json') : airline,\r\n",
        "  airport.get('$id','JsonAirportSchema.json') : airport,\r\n",
        "  flight.get('$id','JsonFlightSchema.json') : flight,\r\n",
        "}\r\n",
        "\r\n",
        "# create resolver instance\r\n",
        "resolver = RefResolver.from_schema(airline, store=schema_store)\r\n",
        "\r\n",
        "# create validator for the base schema\r\n",
        "Validator = validator_for(airline)\r\n",
        "\r\n",
        "# create validator for all of them\r\n",
        "flight_validator = Validator(schema, resolver=resolver)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STNk9fqk74UX"
      },
      "source": [
        "## Creation of json files on flights "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKe0Vmi0C8jK"
      },
      "source": [
        "### Data loading and preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hXjrZcf9_W"
      },
      "source": [
        "def load_csv(filepath):\r\n",
        "  data = pd.read_csv('./2018_1.csv', usecols=list(range(0, 32)),\r\n",
        "                    # reading dates as string to simplify casting \r\n",
        "                    dtype={'CRS_DEP_TIME': str, 'DEP_TIME': str, \r\n",
        "                            'CRS_ARR_TIME': str, 'ARR_TIME': str})\r\n",
        "  \r\n",
        "  # converting crs departure/arrival time into date, these columns NOT contains NaN\r\n",
        "  data['CRS_DEP_TIME'] = pd.to_datetime(data['CRS_DEP_TIME'], format='%H%M')\r\n",
        "  data['CRS_ARR_TIME'] = pd.to_datetime(data['CRS_ARR_TIME'], format='%H%M')\r\n",
        "  # converting real dep/arr time into date, if value is NaN it will be converted to NaT\r\n",
        "  data['DEP_TIME'] = pd.to_datetime(data['DEP_TIME'], errors='coerce', format='%H%M')\r\n",
        "  data['ARR_TIME'] = pd.to_datetime(data['ARR_TIME'], errors='coerce', format='%H%M')\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "r7qV5c5xCSwb",
        "outputId": "712b21a1-e64a-474c-f0a1-222482218cc7"
      },
      "source": [
        "# Example file to check the type of data to be processed \r\n",
        "temp = load_csv('./2018_1.csv')\r\n",
        "temp.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY_OF_MONTH</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>OP_CARRIER</th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>ORIGIN_CITY_NAME</th>\n",
              "      <th>ORIGIN_STATE_NM</th>\n",
              "      <th>DEST</th>\n",
              "      <th>DEST_CITY_NAME</th>\n",
              "      <th>DEST_STATE_NM</th>\n",
              "      <th>CRS_DEP_TIME</th>\n",
              "      <th>DEP_TIME</th>\n",
              "      <th>DEP_DELAY</th>\n",
              "      <th>DEP_DELAY_GROUP</th>\n",
              "      <th>CRS_ARR_TIME</th>\n",
              "      <th>ARR_TIME</th>\n",
              "      <th>ARR_DELAY</th>\n",
              "      <th>ARR_DELAY_GROUP</th>\n",
              "      <th>CANCELLED</th>\n",
              "      <th>CANCELLATION_CODE</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>CRS_ELAPSED_TIME</th>\n",
              "      <th>ACTUAL_ELAPSED_TIME</th>\n",
              "      <th>AIR_TIME</th>\n",
              "      <th>DISTANCE</th>\n",
              "      <th>DISTANCE_GROUP</th>\n",
              "      <th>CARRIER_DELAY</th>\n",
              "      <th>WEATHER_DELAY</th>\n",
              "      <th>NAS_DELAY</th>\n",
              "      <th>SECURITY_DELAY</th>\n",
              "      <th>LATE_AIRCRAFT_DELAY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>9E</td>\n",
              "      <td>SYR</td>\n",
              "      <td>Syracuse, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>DTW</td>\n",
              "      <td>Detroit, MI</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>1900-01-01 05:35:00</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1900-01-01 07:35:00</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>374.0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>9E</td>\n",
              "      <td>SYR</td>\n",
              "      <td>Syracuse, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>LGA</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>1900-01-01 13:58:00</td>\n",
              "      <td>1900-01-01 13:48:00</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1900-01-01 15:19:00</td>\n",
              "      <td>1900-01-01 15:06:00</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>9E</td>\n",
              "      <td>SYR</td>\n",
              "      <td>Syracuse, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>LGA</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>1900-01-01 13:58:00</td>\n",
              "      <td>1900-01-01 14:10:00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1900-01-01 15:19:00</td>\n",
              "      <td>1900-01-01 15:43:00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>9E</td>\n",
              "      <td>SYR</td>\n",
              "      <td>Syracuse, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>LGA</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>1900-01-01 13:58:00</td>\n",
              "      <td>1900-01-01 13:47:00</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1900-01-01 15:19:00</td>\n",
              "      <td>1900-01-01 14:55:00</td>\n",
              "      <td>-24.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9E</td>\n",
              "      <td>SYR</td>\n",
              "      <td>Syracuse, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>LGA</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>New York</td>\n",
              "      <td>1900-01-01 13:58:00</td>\n",
              "      <td>1900-01-01 13:50:00</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1900-01-01 15:19:00</td>\n",
              "      <td>1900-01-01 15:09:00</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  DAY_OF_MONTH  ...  NAS_DELAY SECURITY_DELAY LATE_AIRCRAFT_DELAY\n",
              "0  2018      1            14  ...        NaN            NaN                 NaN\n",
              "1  2018      1             3  ...        NaN            NaN                 NaN\n",
              "2  2018      1             6  ...       12.0            0.0                 0.0\n",
              "3  2018      1             7  ...        NaN            NaN                 NaN\n",
              "4  2018      1             8  ...        NaN            NaN                 NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPQFadwZCrnY"
      },
      "source": [
        "# free memory\r\n",
        "del temp"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JzWmaJK_yNJ"
      },
      "source": [
        "### Functions to create a dictionary (key-value) for columns that contain null values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNNmx4eeANeW"
      },
      "source": [
        "# function that return True if a value is NaN or NaT in case of Date types\r\n",
        "def is_NaN(val):\r\n",
        "  # check string NaN\r\n",
        "  if isinstance(val, str) and not (val == '' or pd.isnull(val)):\r\n",
        "    return False\r\n",
        "  # check NaT/NaN value for date\r\n",
        "  elif not pd.isnull(val):\r\n",
        "    return False\r\n",
        "\r\n",
        "  return True"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YEE5Y2d0KJP"
      },
      "source": [
        "# function that return a py dictionary (json file) with all the information of a\r\n",
        "# specific flight! Only valid values will be added to the fill \r\n",
        "# (i.e. NaN values will not be add, refers to db schema)\r\n",
        "def json_single_flight(fligth_data):\r\n",
        "  time_dic = {}\r\n",
        "\r\n",
        "  # ailine's IATA code\r\n",
        "  time_dic['airline'] = fligth_data.OP_CARRIER\r\n",
        "  # departure time\r\n",
        "  time_dic['crs_dep_time'] = fligth_data.CRS_DEP_TIME.strftime(\"%H:%M\") # provare anche a salvare con .time() e con .to_pydate()\r\n",
        "\r\n",
        "  # saving departure time\r\n",
        "  if not is_NaN(fligth_data.DEP_TIME):\r\n",
        "    time_dic['dep_time'] = fligth_data.DEP_TIME.strftime(\"%H:%M\")\r\n",
        "  # saving delay as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.DEP_DELAY):\r\n",
        "    time_dic['dep_delay'] = int(fligth_data.DEP_DELAY)\r\n",
        "  # saving dep delay group as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.DEP_DELAY_GROUP):\r\n",
        "    time_dic['dep_delay_group'] = int(fligth_data.DEP_DELAY_GROUP)\r\n",
        "  # arrival time (Does not contains NaN)\r\n",
        "  time_dic['crs_arr_time'] = fligth_data.CRS_ARR_TIME.strftime(\"%H:%M\")\r\n",
        "  # saving arrival time\r\n",
        "  if not is_NaN(fligth_data.ARR_TIME):\r\n",
        "    time_dic['arr_time'] = fligth_data.ARR_TIME.strftime(\"%H:%M\")\r\n",
        "  # saving delay as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ARR_DELAY):\r\n",
        "    time_dic['arr_delay'] = int(fligth_data.ARR_DELAY)\r\n",
        "  # saving arrival delay group as integer, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ARR_DELAY_GROUP):\r\n",
        "    time_dic['arr_delay_group'] = int(fligth_data.ARR_DELAY_GROUP)\r\n",
        "\r\n",
        "  # check if flight was cancelled (No NaN)\r\n",
        "  if fligth_data.CANCELLED == 1.0:\r\n",
        "    time_dic['cancelled'] = True\r\n",
        "    time_dic['cancellation_code'] = fligth_data.CANCELLATION_CODE\r\n",
        "  else:\r\n",
        "    time_dic['cancelled'] = False\r\n",
        "  # check if flight was diverted\r\n",
        "  if fligth_data.DIVERTED == 1.0:\r\n",
        "    time_dic['diverted'] = True\r\n",
        "  else:\r\n",
        "    time_dic['diverted'] = False\r\n",
        "\r\n",
        "  # saving crs Elapsed Time of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.CRS_ELAPSED_TIME):\r\n",
        "    time_dic['crs_elapsed_time'] = int(fligth_data.CRS_ELAPSED_TIME)\r\n",
        "  # saving real Elapsed Time of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.ACTUAL_ELAPSED_TIME):\r\n",
        "    time_dic['actual_elapsed_time'] = int(fligth_data.ACTUAL_ELAPSED_TIME)\r\n",
        "  # saving air Time of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.AIR_TIME):\r\n",
        "    time_dic['air_time'] = int(fligth_data.AIR_TIME)\r\n",
        "  # saving carrier_delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.CARRIER_DELAY):\r\n",
        "    time_dic['carrier_delay'] = int(fligth_data.CARRIER_DELAY)\r\n",
        "  # saving weather delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.WEATHER_DELAY):\r\n",
        "    time_dic['weather_delay'] = int(fligth_data.WEATHER_DELAY)\r\n",
        "  # saving nas delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.NAS_DELAY):\r\n",
        "    time_dic['nas_delay'] = int(fligth_data.NAS_DELAY)\r\n",
        "  # saving security delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.SECURITY_DELAY):\r\n",
        "    time_dic['security_delay'] = int(fligth_data.SECURITY_DELAY)\r\n",
        "  # saving late aircraft delay of Flight, cast will be always safe thanks to if\r\n",
        "  if not is_NaN(fligth_data.LATE_AIRCRAFT_DELAY):\r\n",
        "    time_dic['late_aircraft_delay'] = int(fligth_data.LATE_AIRCRAFT_DELAY)\t\r\n",
        "\r\n",
        "  return time_dic"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMaPdMSeBEVf"
      },
      "source": [
        "### Creating JSON files and uploading to mongoDB \r\n",
        "Each files groups year, month, origin airport, destination airport and day of the week <br>\r\n",
        "(**NOTE:** year and month are grouped automatically as the files are already divided!) \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD_RAAKqDfPF"
      },
      "source": [
        "# TODO: va messo un for che per ogni file presente nella cartella esegue i seguenti passi:\r\n",
        "# 1) load (metodo gia implementato)\r\n",
        "# 2) group + creazione + upload (già implementati)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkmN1hTQinE3"
      },
      "source": [
        "# raggruppando per DAY_OF_MONTH per ogni mese vengono circa 130mila file, per DAY_OF_WEEK vengono 30mila\r\n",
        "\r\n",
        "# grouping data\r\n",
        "data_groups = data.groupby(['DAY_OF_WEEK', 'ORIGIN', 'DEST'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6rVdkm_jhB5"
      },
      "source": [
        "# Create a json file and upload it to mongo database for each group of \r\n",
        "# day-origin-destination (Remember: each file contains a specific month and year)\r\n",
        "i = 0\r\n",
        "for group in data_groups:\r\n",
        "  document = {}\r\n",
        "  # list of all flights for a specific day, origin and destination\r\n",
        "  flights = []\r\n",
        "  for flight in group[1].itertuples():\r\n",
        "    # Add basic information in case it is a new group\r\n",
        "    if document == {}:\r\n",
        "      document['year'] = flight.YEAR\r\n",
        "      document['month'] = flight.MONTH\r\n",
        "      document['day_of_month'] = flight.DAY_OF_MONTH\r\n",
        "      document['day_of_week'] = flight.DAY_OF_WEEK\r\n",
        "      document['origin'] = flight.ORIGIN\r\n",
        "      document['destination'] = flight.DEST\r\n",
        "      document['distance'] = int(flight.DISTANCE)\r\n",
        "      document['distance_group'] = flight.DISTANCE_GROUP\r\n",
        "\r\n",
        "    # Append all flight information to the list\r\n",
        "    flights.append(json_single_flight(flight))\r\n",
        "\r\n",
        "  # add the list of all flight to the document\r\n",
        "  document['flights'] = flights\r\n",
        "\r\n",
        "  # If you want to validate json file uncomment the following lines\r\n",
        "  # get json format from dictionary\r\n",
        "  # json_data = json.dumps(document)\r\n",
        "  # print(validateJson(flight_validator,jsonData))\r\n",
        "\r\n",
        "  # writing json to file\r\n",
        "  with open('./json/result' + str(i) + '.json', 'w') as fp:\r\n",
        "    json.dump(document, fp)\r\n",
        "    # alternative way for writing dictionary to json file if dumps is already done before    \r\n",
        "    # fp.write(json_data)\r\n",
        "\r\n",
        "  i = i+1\r\n",
        "  # upload document to mongo instead of writing file\r\n",
        "\r\n",
        "  break"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7uHFoX9azRp"
      },
      "source": [
        "# for download json folder to check mb\r\n",
        "!zip -r temp.zip ./json/ "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}